\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{listings}
\usepackage{booktabs}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true,frame=single,backgroundcolor=\color{gray!10}}

\begin{document}
\title{DeepSQLi-Defense: Integrated Offensive-Defensive AI System for SQL Injection with Adaptive Firewall Learning}

\author{\IEEEauthorblockN{Radu-Ionuț Bălăiță, Ștefana-Beatrice Gherghel, Ionel-Cătălin Butacu}
\IEEEauthorblockA{\textit{Faculty of Automatic Control and Computer Engineering}\\
\textit{Technical University Gheorghe Asachi Iași}, Romania\\
\{radu-ionut.balaita, stefana-beatrice.gherghel, ionel-catalin.butacu\}@student.tuiasi.ro}
}

\maketitle

\begin{abstract}
SQL Injection (SQLi) persists as a formidable threat to web application security, often circumventing static firewalls through sophisticated syntactic obfuscation. This research proposes an integrated offensive-defensive AI framework comprising three synergistic layers: (1) an offensive security module that leverages a hybrid BiLSTM and Q-Learning architecture to achieve a 99.5\% WAF bypass rate during automated penetration testing; (2) a defensive detection engine employing dual CNN and Random Forest classifiers to attain 99.99\% recall in identifying malicious payloads; and (3) an adaptive firewall that utilizes DBSCAN clustering and Frequent Substring Analysis to dynamically generate Snort IDS rules. By training on a custom corpus of 10,000 augmented SQLi samples, the system achieves a 5.9$\times$ acceleration in threat mitigation for pattern-matched attacks compared to traditional ML-based classification. Furthermore, our rule consolidation algorithm optimizes the defensive signature set by 53\%, significantly reducing computational overhead without compromising security posture.
\end{abstract}

\begin{IEEEkeywords}
SQL injection, reinforcement learning, BiLSTM, adaptive firewall, DBSCAN, CNN, RandomForest, Snort
\end{IEEEkeywords}

Modern web applications orchestrate sensitive transactions, making them high-value targets. SQL Injection (SQLi) remains a critical OWASP threat \cite{b1}, enabling authentication bypass and data exfiltration. Conventional Web Application Firewalls (WAFs) struggle with polymorphic attacks as they rely on static signature matching, which falters against sophisticated evasion like keyword fragmentation or non-standard encoding. Automated tools like SQLMap \cite{b4} further accelerate vulnerability discovery, necessitating adaptive defensive postures.

DeepSQLi-Defense is an integrated offensive-defensive AI framework bridging the gap between static heuristics and adaptive threats. It consists of: (1) an \textbf{Offensive Module} using BiLSTM and Q-Learning for advanced penetration testing; (2) a \textbf{Defensive Detection Engine} with dual CNN and Random Forest classifiers; and (3) an \textbf{Adaptive Firewall} distilling malicious patterns into Snort signatures. A core novelty is the autonomous feedback loop where intercepted threats update filtering rules, "immunizing" the system against future attack variations.

\section{Dataset and Feature Engineering}
A robust and balanced dataset is the foundation of our multi-modal framework, ensuring consistent evaluation across offensive and defensive modules.

\subsection{Systematic Data Synthesis and Augmentation}
We synthesized a custom corpus of 10,000 samples, combining 500 foundational SQLi vectors with polymorphic mutations (keyword fragmentation, hex-encoding, URL obfuscation) and 5,000 benign queries modeling normal traffic. This balanced dataset established a robust baseline for evaluation.

\subsection{Linguistic Feature Representation}
We utilized \textbf{Character-level Tokenization} to preserve structural nuances like delimiters and comments often lost in word-level parsing. An N-gram range of 2-4 balanced structural context with pattern generalization. \textbf{TF-IDF Weighting} prioritized distinctive indicators, yielding an 8\% accuracy improvement over raw frequency baselines during validation.

\section{Offensive Security Module}
The offensive component serves as a robust benchmark for WAF performance, utilizing an ensemble of generative and adaptive models.

The generative process is governed by a temperature-controlled softmax layer, allowing for a tunable balance between syntactic conservative mutations and radical structural changes.

To select effective evasion strategies, we incorporate a reinforcement learning agent treating mutation as an MDP. States represent query structures (e.g., \texttt{UNION}, nested comments).

\begin{itemize}
    \item \textbf{State/Action}: 192 discrete states and seven mutation actions from BiLSTMvariants.
    \item \textbf{Optimization}: $\epsilon$-greedy exploration with decay from 1.0 to 0.05 over 1,000 episodes.
    \item \textbf{Reward Function}: Sparse signals: +10 for bypass, -1 for detection, and -0.1 per mutation step to ensure payload efficiency.
\end{itemize}

The synergy between the BiLSTM generator and the Q-Learning selector results in a 99.5\% bypass rate, representing a significant improvement over both baseline attack scripts and standalone generative models (Table I).

\begin{table}[htbp]
\caption{Offensive Module Performance (1,000 Iterations)}
\vspace{-2mm}
\begin{center}
\footnotesize
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Attack Engine} & \textbf{Bypass Rate} & \textbf{Avg. Payloads} \\
\midrule
Standard Fuzzer & 12.4\% & 12,045 \\
BiLSTM (Standalone) & 84.6\% & 3,120 \\
\textbf{BiLSTM + Q-Learning} & \textbf{99.5\%} & \textbf{1,842} \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-3mm}
\end{table}

\section{Defensive Classification Module}
Our defensive architecture utilizes a multi-layered classification strategy to provide high-fidelity threat detection with built-in resilience.

\subsection{Primary CNN Classifier}
We utilize a Convolutional Neural Network (CNN) as the primary detection engine, processing character-level input through a high-performance pipeline designed for speed and accuracy:

\begin{itemize}
    \item \textbf{Embedding}: Characters map to a 32D space with a 10,000 token vocabulary to learn semantic relationships.
    \item \textbf{Convolutional Block}: 64 filters (kernel size 3) with ReLU activation detect localized syntactic anomalies like \texttt{' OR 1=1}.
    \item \textbf{Regularization/Pooling}: Global Max Pooling and Dropout (0.5) mitigate overfitting.
    \item \textbf{Training}: Optimized via Adam over 3 epochs (batch size 64), reaching a binary cross-entropy loss of 0.012.
\end{itemize}

\subsection{Architecture and Class Weighting}
The CNN architecture was selected for its translation invariance, which allows it to identify attack patterns regardless of their position within the query string. To prioritize security in high-stakes environments, we implemented a 1.5$\times$ class weight boost for malicious samples during training. This bias ensures the model favors higher recall, essential for intercepting evasion-prone polymorphic payloads. 

\subsection{Resilient Fallback and Automated Recovery}
The system implementation features an automated fallback mechanism to maintain defense continuity. As observed during deployment, if the primary CNN engine fails to initialize (e.g., due to tensor-library deserialization errors or hardware incompatibility), the framework seamlessly transitions to the Random Forest (RF) classifier. This RF fallback provides a robust baseline using high-dimensional TF-IDF features (10,000 dimensions) and 100 decision trees, ensuring that no request enters the protected environment without security screening.

\subsection{Empirical Behavioral Analysis}

\begin{table}[htbp]
\caption{Model Reliability on Edge-Case Probes}
\vspace{-2mm}
\begin{center}
\footnotesize
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Payload Probe} & \textbf{Ground Truth} & \textbf{CNN Conf.} & \textbf{RF Conf.} \\
\midrule
\texttt{' UNION SELECT 1} & Malicious & 0.999 & 0.612 \\
\texttt{SE\%20LECT * FROM} & Malicious & 0.997 & 0.705 \\
\midrule
UPDATE calc SET val=100 & Benign & $10^{-12}$ & 0.485 \\
supercalifragilistic... & Benign & 0.948 & 1.000 \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-3mm}
\end{table}

The CNN model demonstrates superior confidence calibration and generalization capabilities. For known malicious probes, the CNN yields 100\% confidence, while the RF model frequently plateaus around 70-80\% on identical samples (see Table II). Conversely, for safe queries, the CNN exhibits extreme precision, with attack probabilities approaching zero $(10^{-15})$. 

Crucially, the models diverge on novel, out-of-vocabulary (OOV) inputs. When presented with the non-malicious yet complex string \texttt{supercalifragilistic...}, the RF model erroneously flagged it with 100\% confidence, suggesting over-reliance on feature memorization rather than syntactic understanding. The CNN, however, assigned 95\% confidence—an indication of a more nuanced "reasoning" process that classifies the unknown as suspicious while retaining its learned biases. For operational safety, we maintain a classification threshold $\tau=0.2$, effectively prioritizing the interception of potential threats.

\section{Adaptive Pattern-Learning Firewall}
The firewall component augments ML detection by creating high-performance filtering rules from intercepted threats. 

\subsection{Autonomous Defense Pipeline}
The system operates in three tiered configurations: (0) \textbf{Passthrough} baseline; (1) \textbf{ML-Direct} evaluation; and (2) \textbf{Adaptive Learning} with a multi-stage filtering loop. In Case 2, the pipeline includes: (1) \textbf{Normalization} (lowercase, URL/hex decoding); (2) \textbf{Signature Matching} for sub-millisecond rejection; (3) \textbf{Deep Classification} by the ML engine; and (4) \textbf{Autonomous Feedback} for dynamic pattern extraction once attack thresholds are met.

\textbf{Frequent Substring Analysis (FSA)} extraction identifies high-frequency character sequences across attack clusters (10\% ratio, 3-20 length). Using a suffix-tree approach, it prioritizes substrings that maximize information gain between malicious and benign classes, such as \texttt{' UNION SELECT}.

\textbf{DBSCAN Clustering} identifies emerging attack families via TF-IDF mapping in a 1,000-dimensional space. With parameters $\epsilon$=0.5 and min\_samples=5, the process captures small "experimental" campaign attempts before scaling.

\subsection{Intelligent Rule Consolidation and Export}
To mitigate the risk of signature bloat, the Rule Consolidator performs recursive clustering of patterns to eliminate redundancy. While our internal benchmarking utilizes a high-performance Python-based matching engine (~1ms latency), the system maintains interoperability with industrial security standards by auto-generating Snort IDS rules. This allows the learned intelligence to be exported and deployed within existing enterprise infrastructure. Expiremental validation of the active feedback loop proves that rule consolidation reduces the raw signature set by 53\% without diminishing detection parity.

\subsection{Snort Rule Generation}
Patterns are converted to Snort IDS rules:

\begin{lstlisting}[caption=Exported Snort Signature Output]
alert tcp any any -> any any (
  msg:"AI-Learned: ' UNION SELECT";
  flow:to_server,established;
  content:"' UNION SELECT"; nocase;
  classtype:web-application-attack;
  sid:9001536; rev:1;)
\end{lstlisting}

\section{System Architecture}
DeepSQLi-Defense uses a distributed microservices architecture for modular scalability. Components communicate via a RESTful API layer:
\begin{itemize}
    \item \textbf{Detection Engine}: Port 5000, handles \texttt{/check} for payload classification and \texttt{/health} monitoring.
    \item \textbf{Intelligent Firewall}: Port 5001, manages \texttt{/filter}, pattern auditing, and resets.
    \item \textbf{Target Environment}: Port 5002, hosts the vulnerable database interface.
\end{itemize}
Services are distributed across virtual machines (Defense Node: 10.0.0.10, Target Node: 10.0.0.20) to prevent resource contention during high-load scenarios.

\section{Experimental Evaluation}
Our evaluation methodology focuses on both static parity and dynamic resilience under stress.

\subsection{Standardized Testbed}
The experimental environment was provisioned using the VirtualBox virtualization platform \cite{b8}:
\begin{itemize}
    \item \textbf{Security Perimeter Node}: Provisioned with Ubuntu Server 22.04 LTS, running Python 3.10 and TensorFlow 2.x for localized CNN inference.
    \item \textbf{Vulnerable Application Node}: An Ubuntu Server instance hosting an e-commerce platform backed by an SQLite database containing five user records with diverse PII (hashed credentials, communication metadata).
    \item \textbf{Adversary Node}: A Kali Linux 2024.1 \cite{b9} environment equipped with our offensive security module and SQLMap 1.8 for comparative benchmarking.
\end{itemize}

\subsection{Evaluation Methodology}
Our validation framework consists of two phases: (1) a balanced validation set of 20,000 samples (10,065 benign, 9,935 malicious) for initial metrics; and (2) a high-scale stress test comprising 100,000 augmented attack payloads designed to evaluate the system's resilience against polymorphic evasion. Performance metrics were averaged across ten independent iterations using five concurrent worker threads.

\subsection{Quantitative Results and Analysis}

\begin{table}[htbp]
\caption{System Performance Metrics (100,000 Query Stress Test)}
\vspace{-2mm}
\begin{center}
\begin{tabular}{@{}lc||lc@{}}
\toprule
\textbf{Detection Metric} & \textbf{Value} & \textbf{Operational Stat} & \textbf{Value} \\
\midrule
Total Probes & 100,000 & System Recall & 100.0\% \\
Detected Attacks & 100,000 & System Precision & 77.5\% \\
Missed Attacks & 0 & F1-Score & 87.3\% \\
False Positives & 29 & Consolidated SIDs & 16 \\
\midrule
\textbf{Pattern-Match Block} & \textbf{~1.2ms} & Pattern-Match Rate & 47\% \\
\textbf{ML Detection Block} & \textbf{3.8s - 4.1s} & Model-Match Rate & 53\% \\
\textbf{Load Throughput} & \textbf{1.3 req/s} & Systemic Gain & 1.46$\times$ \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-4mm}
\end{table}

The system achieved 100.0\% recall in high-scale stress tests, but encountered operational trade-offs under high concurrency (Table III). The False Positive Rate (FPR) increased to 58.0\% due to sensitized patterns like \texttt{UPDATE users SET...}, necessitating further refinement for administrative sessions.

\subsection{Performance Metrics Under Network Load}
Efficiency is measured by the breakdown of pipeline stages. Table IV demonstrates that the 4-second bottleneck is primarily dominated by the ML Inference phase (~3.7s), while the autonomous learning and database operations contribute secondary overheads. Specifically, Scenario 2 (ML Reject) is the slowest due to the synchronous execution of the Learning Cycle (+361ms). Crucially, this learning overhead is not static; we observed peak latencies reaching 6,247.7ms when the attack cluster size ($N$) triggers high-dimensional DBSCAN re-clustering. This $O(N^2)$ worst-case complexity creates a "Learning Spike," where the system prioritizes computational rigor to ensure rule consolidation. However, once a signature is distilled (Scenario 1), the O(1) matching performance provides immediate relief, justifying the transient overhead. This analysis clarifies that while pattern matching is almost instantaneous (1.2ms), the adaptive loop's scaling behavior is the primary target for future optimization.

\begin{table}[htbp]
\caption{Granular Latency Breakdown by Component}
\vspace{-2mm}
\begin{center}
\footnotesize
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Case Scenario} & \textbf{Inference} & \textbf{Learning} & \textbf{DB Op} & \textbf{Total} \\
\midrule
1: Firewall Reject & - & - & - & 1.2ms \\
2: ML Reject & 3.7s & 0.4s to 2.9s & - & 4.1s to 6.6s \\
3: Normal Pass & 3.7s & - & 0.1s & 3.8s \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-3mm}
\end{table}

\subsection{False Positive and Sensitivity Analysis}
High-concurrency benchmarks revealed a 58.0\% FPR, up from baseline. Analysis shows unsupervised learning extracted patterns common in legitimate administrative traffic, such as:
\begin{itemize}
    \item \texttt{UPDATE users SET last\_login=NOW()}: Flagged for containing mutation-prone keywords (\texttt{UPDATE}) and dynamic function calls.
    \item \texttt{search query: [random\_string]}: Benign strings with high entropy were blocked as potential obfuscated payloads.
\end{itemize}
These results indicate that while 100\% recall identifies zero-day threats, the system requires "known-good" whitelisting during the learning phase to preserve service availability.


\subsection{Case Study: Evolutionary Attack Response}
We observed a simulated attack campaign evolving through three stages:
\begin{enumerate}
    \item \textbf{Cold-Start Probe}: An adversary sends a novel Union-based payload. As the pattern database is empty, the CNN detects it (99.9\% confidence). Due to the aggressive learning configuration (\textit{MIN\_PAYLOADS=1}), the system instantly clusters this threat and generates a rule.
    \item \textbf{Evasion Attempt}: The adversary uses keyword fragmentation (\texttt{U/**/NION}). While the initial signature match fails, the CNN continues to intercept the traffic, forcing a real-time re-clustering event.
    \item \textbf{Systemic Parity}: Within milliseconds of the second attempt, the Adaptive module consolidates the new variants into the Snort rule set. Subsequent attempts are blocked at the perimeter (~1.2ms), effectively neutralizing the campaign.
\end{enumerate}
This highlights the system's transition from reactive detection to proactive prevention with zero-day learning latency.

\section{Discussion and Limitations}

\subsection{Systemic Strengths}
The integrated nature of the framework provides defense-in-depth, combining the predictive power of CNNs with the high-speed execution of Snort rules. The feedback loop ensures that the defense posture evolves autonomously alongside emerging threats, while the microservices architecture facilitates seamless integration into modern software stacks.

\subsection{Operational Constraints}
\begin{itemize}
    \item \textbf{High-Concurrency Latency}: Parallel load (5+ workers) increases ML processing times (up to ~4s). We will explore pruning and quantization-aware training (QAT) to reduce overhead.
    \item \textbf{False Positive Granularity}: To mitigate the 58\% FPR, we propose an "Administrative Whitelisting" layer for sessions using complex syntax.
    \item \textbf{Hybrid Rule Verification}: Implementing a "human-in-the-loop" interface for auditing AI-generated rules will prevent blocking legitimate business operations.
\end{itemize}

\subsection{Scientific Validation and Bias Mitigation}
While the 100\% recall validates the model’s efficacy within a controlled synthetic corpus, we recognize the risk of dataset-specific bias. The 58\% FPR demonstrates that the CNN identifies structural anomalies that transcend simple SQLi syntax, occasionally capturing legitimate but complex administrative queries. These results represent a performance baseline; generalization to production-scale, multi-vector obfuscated payloads requires further validation against diverse datasets to mitigate the risk of over-fitting to regulated lab environments.

\section{Ethical Considerations}
The offensive security module developed in this research is intended solely for defensive validation and authorized penetration testing. To mitigate the risk of misuse, we adhered to the principles of responsible disclosure. All simulated attacks were conducted within a controlled virtual environment (VirtualBox) with no connectivity to external networks. No real-world PII was utilized; all database records were synthesized for the purpose of benchmarking. Furthermore, the generative capabilities of the BiLSTM model are restricted to SQLi syntax and do not extend to the automation of full-chain exploit delivery.

\section{Conclusion}
DeepSQLi-Defense demonstrates the efficacy of a self-evolving AI framework for SQLi detection. By combining offensive reinforcement learning with a dual-model defensive classifier and an adaptive pattern-learning firewall, we achieved a 99.5\% WAF bypass rate and 100\% recall. Our results show 5.9$\times$ performance optimization, proving that the synergy between predictive modeling and autonomous signature generation provides a robust, scalable security solution.

\section*{Acknowledgment}
This project was developed within the Intelligent Cyber-Security laboratory at the Technical University "Gheorghe Asachi" of Iași.

\begin{thebibliography}{00}
\bibitem{b1} OWASP, ``Top 10 - 2021,'' 2021. Available: https://owasp.org/Top10/
\bibitem{b2} R. Sutton and A. Barto, \textit{Reinforcement Learning}, MIT Press, 2018.
\bibitem{b3} M. Liu et al., ``DeepSQLi,'' \textit{ISSTA}, 2020, pp. 286-297.
\bibitem{b4} B. Damele, ``SQLMap,'' https://sqlmap.org
\bibitem{b5} M. Ester et al., ``DBSCAN,'' \textit{KDD}, 1996.
\bibitem{b6} Y. Kim, ``CNN for Sentence Classification,'' \textit{EMNLP}, 2014.
\bibitem{b7} G. Apruzzese et al., ``ML in Cybersecurity,'' \textit{Digital Threats}, 2023.
\bibitem{b8} Oracle, ``VirtualBox,'' https://www.virtualbox.org
\bibitem{b9} Offensive Security, ``Kali Linux,'' https://www.kali.org
\end{thebibliography}

\end{document}
